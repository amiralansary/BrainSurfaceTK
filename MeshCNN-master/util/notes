48735 edges at red50

before testing move all the train related testoutput files away first, they will be overwritten

gpu01 - twogroups
gpu03 - ready
gpu05 - cosine longer cycle
gpu08 - plateau more features
gpu11 - static low LR
gpu21 - ep50 linear run, second run

cluster - static morefeatures
cluster - 120ep cosine

next

rerun age regression on both havles using best config - more data reduces var error
native runs
inflated run
merged
BATCH SIZE 1 vs BATCH SIZE 2


groups 4
lr scheduler - plateau / cosine (which length of cycle) / static
features -




looking at loss plots it seems that train and test move in sync, so overfitting does not seem to be the problem
-> lr, overshooting

