# -*- coding: utf-8 -*-
"""CW-Brain-Age-Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vG9KkB2emn56Otwry5FCzLoDgDqiPqdZ

# Coursework: Age regression from brain MRI

Predicting the age of patient from a brain MRI scan can have diagnostic value for a number of diseases that may cause structural changes and potential damage to the brain. A discrepancy between the predicted age and the real, chronological age of a patient might indicate the presence of disease. This requires an accurate predictor of brain age which may be learned from a set of healthy reference subjects, given their brain MRI data and their actual age.

The objective for the coursework is to implement different supervised learning approaches for age regression from brain MRI. We provided data from a total of 652 healthy subjects, that is split into different development sets and a held-out test set on which you will evaluate your final prediction accuracy.

Each approach will require a processing pipeline with different components that you will need to implement using methods that were discussed in the lectures and tutorials. There are three dedicated parts in the Jupyter notebook for each approach which contain some detailed instructions and some helper code.

You may find some useful ideas and implementations in the tutorial notebooks. Once you have implemented all approaches and obtained results from your experiments, we ask you to write a short summary report. The reports should contain a short introduction, description of each of your methods and the individual processing steps, your results with a brief discussion. The report should also include some figures and plots to support your findings.

#### Read the text descriptions and the provided code cells carefully and look out for the cells marked with 'TASK' and 'ADD YOUR CODE HERE'.

### Getting started and familiarise ourselves with the data

The following cells provide some helper functions to load the data, and provide some overview and visualisation of the statistics over the total population of 652 subjects. The data will be split into different subsets to be used for different parts of the coursework. There is a set of 52 subjects to be used in part A to develop an image segmentation method (47 for training, 5 for validation). We then use 500 subjects for training and cross-validation of age regression approaches in part A, B and C. A remaining set of 100 subjects is used to test the final age prediction accuracy and will be made available towards the end of the coursework.

### Running on Colab or Azure
"""

# ! pip install SimpleITK==1.2.2 
# ! wget https://www.doc.ic.ac.uk/~bglocker/teaching/notebooks/brainage-data.zip
# ! unzip brainage-data.zip

# # data directory
data_dir = 'data/brain_age/'

"""### Running on DoC lab machines"""

# # data directory
# data_dir = '/vol/lab/course/416/data/brain_age/'

"""Let's start by loading the meta data of the entire population, that is the data containing information about the subject IDs, their age, and gender."""

# data directory
data_dir = 'data/brain_age/'

# Read the meta data using pandas
import pandas as pd

meta_data_all = pd.read_csv(data_dir + 'meta/meta_data_all.csv')
meta_data_all.head() # show the first five data entries

"""Let's have a look at some population statistics."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.pyplot as plt
import seaborn as sns

meta_data = meta_data_all

sns.catplot(x="gender_text", data=meta_data, kind="count")
plt.title('Gender distribution')
plt.xlabel('Gender')
plt.show()

sns.distplot(meta_data['age'], bins=[10,20,30,40,50,60,70,80,90])
plt.title('Age distribution')
plt.xlabel('Age')
plt.show()

plt.scatter(range(len(meta_data['age'])),meta_data['age'], marker='.')
plt.grid()
plt.xlabel('Subject')
plt.ylabel('Age')
plt.show()

"""### Set up a simple medical image viewer and import SimpleITK"""

import numpy as np
import SimpleITK as sitk
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

from ipywidgets import interact, fixed
from IPython.display import display
np.set_printoptions(3)

# Calculate parameters low and high from window and level
def wl_to_lh(window, level):
    low = level - window/2
    high = level + window/2
    return low,high

def display_image(img, x=None, y=None, z=None, window=None, level=None, colormap='gray', crosshair=False):
    # Convert SimpleITK image to NumPy array
    img_array = sitk.GetArrayFromImage(img)
    
    # Get image dimensions in millimetres
    size = img.GetSize()
    spacing = img.GetSpacing()
    width  = size[0] * spacing[0]
    height = size[1] * spacing[1]
    depth  = size[2] * spacing[2]
    
    if x is None:
        x = np.floor(size[0]/2).astype(int)
    if y is None:
        y = np.floor(size[1]/2).astype(int)
    if z is None:
        z = np.floor(size[2]/2).astype(int)
    
    if window is None:
        window = np.max(img_array) - np.min(img_array)
    
    if level is None:
        level = window / 2 + np.min(img_array)
    
    low,high = wl_to_lh(window,level)

    # Display the orthogonal slices
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4))

    ax1.imshow(img_array[z,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))
    ax2.imshow(img_array[:,y,:], origin='lower', cmap=colormap, clim=(low, high), extent=(0, width,  0, depth))
    ax3.imshow(img_array[:,:,x], origin='lower', cmap=colormap, clim=(low, high), extent=(0, height, 0, depth))

    # Additionally display crosshairs
    if crosshair:
        ax1.axhline(y * spacing[1], lw=1)
        ax1.axvline(x * spacing[0], lw=1)
        ax2.axhline(z * spacing[2], lw=1)
        ax2.axvline(x * spacing[0], lw=1)
        ax3.axhline(z * spacing[2], lw=1)
        ax3.axvline(y * spacing[1], lw=1)

    plt.show()

def display_z_plane_images(img, x=None, y=None, z=None, window=None, level=None, colormap='gray', crosshair=False):
    # Convert SimpleITK image to NumPy array
    img_array = sitk.GetArrayFromImage(img)
    
    # Get image dimensions in millimetres
    size = img.GetSize()
    spacing = img.GetSpacing()
    width  = size[0] * spacing[0]
    height = size[1] * spacing[1]
    depth  = size[2] * spacing[2]
    
    if x is None:
        x = np.floor(size[2]/2).astype(int)
    if y is None:
        y = np.floor(size[2]*2/3).astype(int)
    if z is None:
        z = np.floor(size[2]/3).astype(int)
        a = np.floor(size[2]/4).astype(int)
        b = np.floor(size[2]*3/4).astype(int)

    if window is None:
        window = np.max(img_array) - np.min(img_array)
    
    if level is None:
        level = window / 2 + np.min(img_array)
    
    low,high = wl_to_lh(window,level)

    # Display the orthogonal slices
    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 4))

    ax1.imshow(img_array[a,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))
    ax2.imshow(img_array[z,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))
    ax3.imshow(img_array[x,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))
    ax4.imshow(img_array[y,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))
    ax5.imshow(img_array[b,:,:], cmap=colormap, clim=(low, high), extent=(0, width, height, 0))


    # Additionally display crosshairs
    if crosshair:
        ax1.axhline(y * spacing[1], lw=1)
        ax1.axvline(x * spacing[0], lw=1)
        ax2.axhline(z * spacing[2], lw=1)
        ax2.axvline(x * spacing[0], lw=1)
        ax3.axhline(z * spacing[2], lw=1)
        ax3.axvline(y * spacing[1], lw=1)

    plt.show()

def interactive_view(img):
    size = img.GetSize() 
    img_array = sitk.GetArrayFromImage(img)
    interact(display_image,img=fixed(img),
             x=(0, size[0] - 1),
             y=(0, size[1] - 1),
             z=(0, size[2] - 1),
             window=(0,np.max(img_array) - np.min(img_array)),
             level=(np.min(img_array),np.max(img_array)));

"""### Imaging data

Let's check out the imaging data that is available for each subject. This cell also shows how to retrieve data given a particular subject ID from the meta data.
"""

# Subject with index 0
ID = meta_data['subject_id'][0]
age = meta_data['age'][0]

# Image
image_filename = data_dir + 'images/sub-' + ID + '_T1w_unbiased.nii.gz'
img = sitk.ReadImage(image_filename)

# Mask
mask_filename = data_dir + 'masks/sub-' + ID + '_T1w_brain_mask.nii.gz'
msk = sitk.ReadImage(mask_filename)

# Grey matter map
gm_filename = data_dir + 'greymatter/wc1sub-' + ID + '_T1w.nii.gz'
gm = sitk.ReadImage(gm_filename)

print('Imaging data of subject ' + ID + ' with age ' + str(age))

print('\nMR Image (used in part A)')
display_image(img, window=400, level=200)

print('Brain mask (used in part A)')
display_image(msk)

print('Spatially normalised grey matter maps (used in part B and C)')
display_image(gm)

"""## Part A: Volume-based regression using brain structure segmentation

The first approach aims to regress the age of a subject using the volumes of brain tissues as features. The brain structures include grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF). It is known that with increasing age the ventricles enlarge (filled with CSF), while it is assumed that grey and white matter volume may decrease over time. However, as overall brain volume varies across individuals, taking the absolute volumes of tissues might not be predictive. Instead, relative volumes need to be computed as the ratios between each tissue volume and overall brain volume. To this end, a four-class (GM, WM, CSF, and background) brain segmentation needs to be implemented which will be trained using a total of 52 subjects (47 for training, 5 for validation). The segmentation method is then applied to the remaining 600 brain scans which will be used to train and test the age regression. Brain masks are provided which have been generated with a state-of-the-art neuroimaging brain extraction tool.

Different regression techniques should be explored, and it might be beneficial to investigate what the best set of features is for this task. Are all volume features equally useful, or is it even better to combine some of them and create new features. How does a simple linear regression perform compared to a model with higher order polynomials? Do you need regularisation? How about other regression methods such as regression trees, SVMs or neural networks? The accuracy of different methods should be evaluated using two-fold cross-validation on the set of 500 subjects, and average age prediction accuracy should be compared and reported appropriately. The final prediction accuracy will be evaluated on a hold-out set of 100 subjects.

*Note:* For part A, only the MR images and the brain masks should be used from the imaging data. The spatially normalised grey matter maps are used in part B and C only. If you struggle with task A-1, you can continue with A-2 using the provided reference segmentations in subfolder `segs_refs`.

### TASK A-1: Brain tissue segmentation

Implement a CNN model for brain tissue segmentation which can provide segmentations of GM, WM, and CSF. For this task (and only for this task), we provide a subset of 52 subjects which are split into 47 images for training and 5 for validation. The template code below has the data handling and main training routines already implemented, so you can focus on implementing a suitable CNN model. A simple model is provided, but this won't perform very well.

Once your model is trained and you are happy with the results on the validation data you should apply it to the 500 subjects later used for training the age regressor. We provide reference segmentations in a subfolder `segs_refs` for all subjects. Calculate Dice similarity coefficients per tissue when comparing your predicted segmentations to the reference segmentations. Summarise the statistics of the 500 Dice scores for each tissue class in [box-and-whisker-plots](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html).

*Note:* Implementing a full-fledged machine learning pipeline with training and testing procedures in Jupyter notebooks is a bit cumbersome and a pain to debug. Also, running bigger training tasks can be unstable. The code below should work as is on your VM. However, if you want to get a bit more serious about implementing an advanced CNN approach for image segmentation, you may want to move code into separate Python scripts and run these from the terminal.

#### Imports
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

"""#### Data Helpers"""

def zero_mean_unit_var(image, mask):
    """Normalizes an image to zero mean and unit variance."""

    img_array = sitk.GetArrayFromImage(image)
    img_array = img_array.astype(np.float32)

    msk_array = sitk.GetArrayFromImage(mask)

    mean = np.mean(img_array[msk_array>0])
    std = np.std(img_array[msk_array>0])

    if std > 0:
        img_array = (img_array - mean) / std
        img_array[msk_array==0] = 0

    image_normalised = sitk.GetImageFromArray(img_array)
    image_normalised.CopyInformation(image)

    return image_normalised


def resample_image(image, out_spacing=(1.0, 1.0, 1.0), out_size=None, is_label=False, pad_value=0):
    """Resamples an image to given element spacing and output size."""

    original_spacing = np.array(image.GetSpacing())
    original_size = np.array(image.GetSize())

    if out_size is None:
        out_size = np.round(np.array(original_size * original_spacing / np.array(out_spacing))).astype(int)
    else:
        out_size = np.array(out_size)

    original_direction = np.array(image.GetDirection()).reshape(len(original_spacing),-1)
    original_center = (np.array(original_size, dtype=float) - 1.0) / 2.0 * original_spacing
    out_center = (np.array(out_size, dtype=float) - 1.0) / 2.0 * np.array(out_spacing)

    original_center = np.matmul(original_direction, original_center)
    out_center = np.matmul(original_direction, out_center)
    out_origin = np.array(image.GetOrigin()) + (original_center - out_center)

    resample = sitk.ResampleImageFilter()
    resample.SetOutputSpacing(out_spacing)
    resample.SetSize(out_size.tolist())
    resample.SetOutputDirection(image.GetDirection())
    resample.SetOutputOrigin(out_origin.tolist())
    resample.SetTransform(sitk.Transform())
    resample.SetDefaultPixelValue(pad_value)

    if is_label:
        resample.SetInterpolator(sitk.sitkNearestNeighbor)
    else:
        resample.SetInterpolator(sitk.sitkBSpline)

    return resample.Execute(image)


class ImageSegmentationDataset(Dataset):
    """Dataset for image segmentation."""

    def __init__(self, file_list_img, file_list_seg, file_list_msk, img_spacing, img_size):
        self.samples = []
        self.img_names = []
        self.seg_names = []
        for idx, _ in enumerate(tqdm(range(len(file_list_img)), desc='Loading Data')):
            img_path = file_list_img[idx]
            seg_path = file_list_seg[idx]
            msk_path = file_list_msk[idx]

            img = sitk.ReadImage(img_path, sitk.sitkFloat32)

            seg = sitk.ReadImage(seg_path, sitk.sitkInt64)

            msk = sitk.ReadImage(msk_path, sitk.sitkUInt8)

            #pre=processing
            img = zero_mean_unit_var(img, msk)
            img = resample_image(img, img_spacing, img_size, is_label=False)
            seg = resample_image(seg, img_spacing, img_size, is_label=True)
            msk = resample_image(msk, img_spacing, img_size, is_label=True)
########################################
            sample = {'img': img, 'seg': seg, 'msk': msk}

            self.samples.append(sample)
            self.img_names.append(os.path.basename(img_path))
            self.seg_names.append(os.path.basename(seg_path))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, item):
        sample = self.samples[item]

        image = torch.from_numpy(sitk.GetArrayFromImage(sample['img'])).unsqueeze(0)
        seg = torch.from_numpy(sitk.GetArrayFromImage(sample['seg'])).unsqueeze(0)
        msk = torch.from_numpy(sitk.GetArrayFromImage(sample['msk'])).unsqueeze(0)

        return {'img': image, 'seg': seg, 'msk': msk}

    def get_sample(self, item):
        return self.samples[item]

    def get_img_name(self, item):
        return self.img_names[item]

    def get_seg_name(self, item):
        return self.seg_names[item]

"""#### Check that the GPU is up and running"""

cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda:" + cuda_dev if use_cuda else "cpu")

print('Device: ' + str(device))
if use_cuda:
    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))

"""#### Config and hyper-parameters

Here we set some default hyper-parameters and a starting configuration for the image resolution and others.

**TASK: This needs to be revisited to optimise these values. In particular, you may want to run your final model on higher resolution images.**
"""

rnd_seed = 42 #fixed rand seed

# img_size = [32, 32, 32]
img_size = [64, 64, 64]
img_spacing = [3, 3, 3]

num_epochs = 200
learning_rate = 1e-3
batch_size = 2
val_interval = 10

num_classes = 4

out_dir = './output'

# Create output directory
if not os.path.exists(out_dir):
    os.makedirs(out_dir)

"""#### Loading and pre-processing of training and validation data"""

meta_data_seg_train = pd.read_csv(data_dir + 'meta/meta_data_seg_train.csv')
ids_seg_train = list(meta_data_seg_train['subject_id'])
files_seg_img_train = [data_dir + 'images/sub-' + f + '_T1w_unbiased.nii.gz' for f in ids_seg_train]
files_seg_seg_train = [data_dir + 'segs_refs/sub-' + f + '_T1w_seg.nii.gz' for f in ids_seg_train]
files_seg_msk_train = [data_dir + 'masks/sub-' + f + '_T1w_brain_mask.nii.gz' for f in ids_seg_train]

meta_data_seg_val = pd.read_csv(data_dir + 'meta/meta_data_seg_val.csv')
ids_seg_val = list(meta_data_seg_val['subject_id'])
files_seg_img_val = [data_dir + 'images/sub-' + f + '_T1w_unbiased.nii.gz' for f in ids_seg_val]
files_seg_seg_val = [data_dir + 'segs_refs/sub-' + f + '_T1w_seg.nii.gz' for f in ids_seg_val]
files_seg_msk_val = [data_dir + 'masks/sub-' + f + '_T1w_brain_mask.nii.gz' for f in ids_seg_val]

"""We apply some standard pre-processing on the data such as intensity normalization (zero mean unit variance) and downsampling according to the configuration above.

**You may want to use initially the validation data with 5 subjects for training which is more efficient when debugging your training routine and model implementation. Make sure to later train your final model on the actual training data.**
"""

# LOAD ACTUAL TRAINING DATA
#dataset_train = ImageSegmentationDataset(files_seg_img_train, files_seg_seg_train, files_seg_msk_train, img_spacing, img_size)
# LOAD VALIDATION DATA AS TRAINING FOR QUICK DEBUGGING
dataset_train = ImageSegmentationDataset(files_seg_img_val, files_seg_seg_val, files_seg_msk_val, img_spacing, img_size)
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)

dataset_val = ImageSegmentationDataset(files_seg_img_val, files_seg_seg_val, files_seg_msk_val, img_spacing, img_size)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1, shuffle=False)

"""#### Visualise training example

Just to check how a training image looks like after pre-processing.
"""

sample = dataset_train.get_sample(0)
img_name = dataset_train.get_img_name(0)
seg_name = dataset_train.get_seg_name(0)
print('Image: ' + img_name)
display_image(sample['img'], window=5, level=0)
print('Segmentation')
display_image(sitk.LabelToRGB(sample['seg']))
print('Mask')
display_image(sample['msk'])

def Dice_score(preds, ys):
    preds_flat = preds.flatten()
    ys_flat = ys.flatten()
    assert len(ys_flat) == len(preds_flat), "Tensors are of different sizes"

    D = {'Background':0, 'GM':0, 'WM':0, 'CSF':0}
    for n, metric in enumerate(D):
        TP = torch.where((preds_flat == ys_flat) & (ys_flat == n))[0]
        d = 2 * len(TP) / (len(torch.where(ys_flat == n)[0]) + len(torch.where(preds_flat == n)[0]))
        D[metric] = d

    return D

def accuracy(preds, ys):
    preds = preds.detach().cpu().numpy().flatten()
    ys = ys.detach().cpu().numpy().flatten()
    conf_mat = confusion_matrix(ys, preds)
    accuracy = conf_mat.diagonal().sum() / conf_mat.sum()
    return accuracy

"""#### The Model

**TASK:** This is the **key part of task A-1** where you have to design a suitable CNN model for brain segmentation. The simple model provided below works to some degree (it let's you run through the upcoming cells), but it will not perform very well. Use what you learned in the lectures to come up with a good architecture. Start with a simple, shallow model and only increase complexity (e.g., number of layers) if needed.
"""

# ! git clone https://github.com/kenshohara/3D-ResNets-PyTorch.git
# ! mv 3D-ResNets-PyTorch ResNet_Three_Dim
# ! touch ResNet_Three_Dim/__init__.py
# from ResNet_Three_Dim.models import resnet
# resnet = resnet.resnet10()

########################################
# BUILD A BETTER MODEL HERE
########################################

# import torch
# import torch.nn as nn

# class First3D(nn.Module):
#     def __init__(self, in_channels, middle_channels, out_channels, dropout=False):
#         super(First3D, self).__init__()

#         layers = [
#             nn.Conv3d(in_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, out_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(out_channels),
#             nn.ReLU(inplace=True)
#         ]

#         if dropout:
#             assert 0 <= dropout <= 1, 'dropout must be between 0 and 1'
#             layers.append(nn.Dropout3d(p=dropout))

#         self.first = nn.Sequential(*layers)

#     def forward(self, x):
#         return self.first(x)


# class Encoder3D(nn.Module):
#     def __init__(
#             self, in_channels, middle_channels, out_channels,
#             dropout=False, downsample_kernel=2
#     ):
#         super(Encoder3D, self).__init__()

#         layers = [
#             nn.MaxPool3d(kernel_size=downsample_kernel),
#             nn.Conv3d(in_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, out_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(out_channels),
#             nn.ReLU(inplace=True)
#         ]

#         if dropout:
#             assert 0 <= dropout <= 1, 'dropout must be between 0 and 1'
#             layers.append(nn.Dropout3d(p=dropout))

#         self.encoder = nn.Sequential(*layers)

#     def forward(self, x):
#         return self.encoder(x)


# class Center3D(nn.Module):
#     def __init__(self, in_channels, middle_channels, out_channels, deconv_channels, dropout=False):
#         super(Center3D, self).__init__()

#         layers = [
#             nn.MaxPool3d(kernel_size=2),
#             nn.Conv3d(in_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, out_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(out_channels),
#             nn.ReLU(inplace=True),
#             nn.ConvTranspose3d(out_channels, deconv_channels, kernel_size=2, stride=2)
#         ]

#         if dropout:
#             assert 0 <= dropout <= 1, 'dropout must be between 0 and 1'
#             layers.append(nn.Dropout3d(p=dropout))

#         self.center = nn.Sequential(*layers)

#     def forward(self, x):
#         return self.center(x)


# class Decoder3D(nn.Module):
#     def __init__(self, in_channels, middle_channels, out_channels, deconv_channels, dropout=False):
#         super(Decoder3D, self).__init__()

#         layers = [
#             nn.Conv3d(in_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, out_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(out_channels),
#             nn.ReLU(inplace=True),
#             nn.ConvTranspose3d(out_channels, deconv_channels, kernel_size=2, stride=2)
#         ]

#         if dropout:
#             assert 0 <= dropout <= 1, 'dropout must be between 0 and 1'
#             layers.append(nn.Dropout3d(p=dropout))

#         self.decoder = nn.Sequential(*layers)

#     def forward(self, x):
#         return self.decoder(x)


# class Last3D(nn.Module):
#     def __init__(self, in_channels, middle_channels, out_channels, softmax=False):
#         super(Last3D, self).__init__()

#         layers = [
#             nn.Conv3d(in_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, middle_channels, kernel_size=3, padding=1),
#             nn.BatchNorm3d(middle_channels),
#             nn.ReLU(inplace=True),
#             nn.Conv3d(middle_channels, out_channels, kernel_size=1),
#             nn.Softmax(dim=1)
#         ]

#         self.first = nn.Sequential(*layers)

#     def forward(self, x):
#         return self.first(x)


# class UNet(nn.Module):
#     def __init__(self, in_channels, out_channels, conv_depths=(64, 128, 256, 512, 1024)):
#         assert len(conv_depths) > 2, 'conv_depths must have at least 3 members'

#         super(SimpleNet3D, self).__init__()

#         # defining encoder layers
#         encoder_layers = []
#         encoder_layers.append(First3D(in_channels, conv_depths[0], conv_depths[0]))
#         encoder_layers.extend([Encoder3D(conv_depths[i], conv_depths[i + 1], conv_depths[i + 1])
#                                for i in range(len(conv_depths)-2)])

#         # defining decoder layers
#         decoder_layers = []
#         decoder_layers.extend([Decoder3D(2 * conv_depths[i + 1], 2 * conv_depths[i], 2 * conv_depths[i], conv_depths[i])
#                                for i in reversed(range(len(conv_depths)-2))])
#         decoder_layers.append(Last3D(conv_depths[1], conv_depths[0], out_channels))

#         # encoder, center and decoder layers
#         self.encoder_layers = nn.Sequential(*encoder_layers)
#         self.center = Center3D(conv_depths[-2], conv_depths[-1], conv_depths[-1], conv_depths[-2])
#         self.decoder_layers = nn.Sequential(*decoder_layers)

#     def forward(self, x, return_all=False):
#         x_enc = [x]
#         for enc_layer in self.encoder_layers:
#             x_enc.append(enc_layer(x_enc[-1]))

#         x_dec = [self.center(x_enc[-1])]
#         for dec_layer_idx, dec_layer in enumerate(self.decoder_layers):
#             x_opposite = x_enc[-1-dec_layer_idx]
#             x_cat = torch.cat(
#                 [pad_to_shape(x_dec[-1], x_opposite.shape), x_opposite],
#                 dim=1
#             )
#             x_dec.append(dec_layer(x_cat))

#         if not return_all:
#             return x_dec[-1]
#         else:
#             return x_enc + x_dec


# def pad_to_shape(this, shp):
#     """
#     Pads this image with zeroes to shp.
#     Args:
#         this: image tensor to pad
#         shp: desired output shape
#     Returns:
#         Zero-padded tensor of shape shp.
#     """
#     if len(shp) == 4:
#         pad = (0, shp[3] - this.shape[3], 0, shp[2] - this.shape[2])
#     elif len(shp) == 5:
#         pad = (0, shp[4] - this.shape[4], 0, shp[3] - this.shape[3], 0, shp[2] - this.shape[2])
#     return F.pad(this, pad)

# # torch.cuda.empty_cache()
# # batch_samples = next(iter(dataloader_train))
# # model = UNet3D(1, num_classes).to(device)
# # model.train()

# # img, seg, msk = batch_samples['img'].to(device), batch_samples['seg'].to(device), batch_samples['msk'].to(device)
# # print(img.shape, seg.shape)
# # prd = model(img)
# # print(prd.shape)

# # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# # model = SimpleNet3D(n_class=6)
# # model = model.to(device)

# # # check keras-like model summary using torchsummary
# # from torchsummary import summary
# # summary(model, input_size=(3, 224, 224, 224))

########################################
# BUILD A BETTER MODEL HERE
########################################

# class SimpleNet3D(nn.Module):

#     def __init__(self, num_classes, channels=None):
#         super(SimpleNet3D, self).__init__()
#         self.conv1 = nn.Conv3d(1, 4, kernel_size=3, padding=1)
#         self.conv2 = nn.Conv3d(4, 8, kernel_size=3, padding=1)
#         self.conv3 = nn.Conv3d(8, 4, kernel_size=3, padding=1)
#         self.conv4 = nn.Conv3d(4, num_classes, kernel_size=3, padding=1)

#     def forward(self, x):
#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
#         x = F.relu(self.conv3(x))
#         x = self.conv4(x)
#         return F.softmax(x, dim=1)

# class SimpleNet3D(nn.Module):

#     def __init__(self, num_classes):
#         super(SimpleNet3D, self).__init__()
#         self.conv1 = nn.Conv3d(1, 20, kernel_size=3, padding=1)
#         self.conv2 = nn.Conv3d(20, 4, kernel_size=3, padding=1)
#         self.conv_f = nn.Conv3d(4, num_classes, kernel_size=1, padding=0)

#     def forward(self, x):
#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
#         x = self.conv_f(x)
#         return F.softmax(x, dim=1)

# class SimpleNet3D(nn.Module):

#     def __init__(self, num_classes):
#         super(SimpleNet3D, self).__init__()
#         self.conv1 = nn.Conv3d(1, 20, kernel_size=5, padding=1)
#         self.conv2 = nn.Conv3d(20, 20, kernel_size=5, padding=2)
#         self.conv3 = nn.Conv3d(20, 20, kernel_size=3, padding=2)
#         self.conv_f = nn.Conv3d(20, num_classes, kernel_size=1, padding=0)

#     def forward(self, x):
#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
#         x = F.relu(self.conv3(x))
#         x = self.conv_f(x)
#         return F.softmax(x, dim=1)


class SimpleNet3D(nn.Module):

    def __init__(self, num_classes):
        super(SimpleNet3D, self).__init__()
        self.conv1 = nn.Conv3d(1, 20, kernel_size=5, padding=1)
        self.conv2 = nn.Conv3d(20, 40, kernel_size=5, padding=2)
        self.conv3 = nn.Conv3d(40, 20, kernel_size=3, padding=2)
        self.conv_f = nn.Conv3d(20, num_classes, kernel_size=1, padding=0)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = self.conv_f(x)
        return F.softmax(x, dim=1)


# class SimpleNet3D(nn.Module):

#     def __init__(self, num_classes, channels=None):
#         super(SimpleNet3D, self).__init__()
#         self.conv1 = nn.Conv3d(1, 4, kernel_size=3, padding=1, stride=1)
#         self.conv2 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=2)
#         self.conv3 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)
#         self.conv4 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=2)
#         self.conv5 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)

#         self.conv_1 = nn.ConvTranspose3d(4, 4, kernel_size=4, padding=1, stride=2)
#         self.conv_2 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)
#         self.conv_3 = nn.ConvTranspose3d(4, 4, kernel_size=4, padding=1, stride=2)
#         self.conv_4 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)

#         self.conv_f = nn.Conv3d(4, num_classes, kernel_size=3, padding=1)

#     def forward(self, x):
#         x = F.relu(self.conv1(x))        
#         s_1 = x.clone()
#         x = F.relu(self.conv2(x))
#         s_2 = x.clone()
#         x = F.relu(self.conv3(x))
#         x = F.relu(self.conv4(x))
#         x = F.relu(self.conv5(x))

#         x = F.relu(self.conv_1(x))
#         x = F.relu(self.conv_2(x))
#         x += s_2
#         x = F.relu(self.conv_3(x))
#         x += s_1
#         x = F.relu(self.conv_4(x))

#         x = F.relu(self.conv_f(x))
#         return F.softmax(x, dim=1)


# class SimpleNet3D(nn.Module):

#     def __init__(self, num_classes, channels=None):
#         super(SimpleNet3D, self).__init__()
#         self.conv1 = nn.Conv3d(1, 20, kernel_size=3, padding=1)
#         self.conv2 = nn.Conv3d(20, 4, kernel_size=3, padding=1)

#         self.conv_1 = nn.Conv3d(1, 4, kernel_size=3, padding=1, stride=2)
#         self.conv_2 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)
#         self.tran_conv_1 = nn.ConvTranspose3d(4, 4, kernel_size=4, padding=1, stride=2)
#         self.conv_3 = nn.Conv3d(4, 4, kernel_size=3, padding=1, stride=1)

#         self.conv_f = nn.Conv3d(4, num_classes, kernel_size=3, padding=1)

#     def forward(self, x):
#         y = x.clone()

#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
        
#         y = F.relu(self.conv_1(y))
#         y = F.relu(self.conv_2(y))
#         y = F.relu(self.tran_conv_1(y))
#         y = F.relu(self.conv_3(y))

#         x += y
#         x = self.conv_f(x)

#         return F.softmax(x, dim=1)


# torch.cuda.empty_cache()
# batch_samples = next(iter(dataloader_train))
# model = SimpleNet3D(num_classes=num_classes).to(device)
# model.train()

# # img, seg, msk = batch_samples['img'].to(device), batch_samples['seg'].to(device), batch_samples['msk'].to(device)
# img, seg, msk = batch_samples['img'].to(device), batch_samples['seg'].to(device), batch_samples['msk'].to(device)
# print(img.shape, seg.shape)
# prd = model(img)
# print(prd.shape)

"""#### TRAINING

Below is an implementation of a full training procedure including a loop for intermediate evaluation of the model on the validation data. Feel free to modify this procedure. For example, in addition to the loss you may want to monitor precision, recall and Dice scores (or others).
"""

torch.cuda.empty_cache()
model_dir = os.path.join(out_dir, 'model')
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

torch.manual_seed(rnd_seed) #fix rand seed

num_epochs = 200

# model = UNet3D(in_channels=1, out_channels=num_classes).to(device)
model = SimpleNet3D(num_classes).to(device)
model.train()
    
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

loss_train_log = []
loss_val_log = []
epoch_val_log = []
    
print('START TRAINING...')
for epoch in range(1, num_epochs + 1):
# for epoch in range(1,2):
    # Training
    for batch_idx, batch_samples in enumerate(dataloader_train):
        img, seg = batch_samples['img'].to(device), batch_samples['seg'].to(device)         # Shape = (batch_size, num_channels, x, y, z)
        optimizer.zero_grad()
        prd = model(img)
        prd_flat = prd.view(prd.size(0), prd.size(1), -1)
        seg_flat = seg.view(seg.size(0), seg.size(1), -1)
        loss = F.cross_entropy(prd_flat, seg_flat.squeeze(1))
        loss.backward()
        optimizer.step()
        torch.cuda.empty_cache()

    loss_train_log.append(loss.item())

    print('+ TRAINING \tEpoch: {} \tLoss: {:.6f}'.format(epoch, loss.item()))
    
    # Validation
    if epoch == 1 or epoch % val_interval == 0:
        loss_val = 0
        sum_pts = 0
        with torch.no_grad():
            for data_sample in dataloader_val:
                img, seg = data_sample['img'].to(device), data_sample['seg'].to(device)
                prd = model(img)
                prd_flat = prd.view(prd.size(0), prd.size(1), -1)
                seg_flat = seg.view(seg.size(0), seg.size(1), -1)
                loss_val += F.cross_entropy(prd_flat, seg_flat.squeeze(1), reduction='sum').item()
                sum_pts += seg_flat.size(2)
                
        prd = torch.argmax(prd, dim=1)
        prediction = sitk.GetImageFromArray(prd.cpu().squeeze().numpy().astype(np.uint8)) 
        segment = sitk.GetImageFromArray(seg.cpu().squeeze().numpy().astype(np.uint8))        

        loss_val /= sum_pts

        loss_val_log.append(loss_val)
        epoch_val_log.append(epoch)
        D = Dice_score(prd, seg)
        acc = accuracy(prd, seg)

        print('---------------------------------------------------------------')
        print('+ VALIDATE \tEpoch: {} \tLoss: {:.6f}\t Accuracy: {:.2f}%'.format(epoch, loss_val, acc*100))
        print(f"+ VALIDATE \tBground: {D['Background']:.4f} \tGM: {D['GM']:.4f} \tWM: {D['WM']:.4f} \tCSF: {D['CSF']:.4f}")
        # display_image(sitk.LabelToRGB(prediction))
        # display_image(sitk.LabelToRGB(segment))
        display_z_plane_images(sitk.LabelToRGB(prediction))
        display_z_plane_images(sitk.LabelToRGB(segment))
        print('---------------------------------------------------------------')

torch.save(model.state_dict(), os.path.join(model_dir, 'model.pt'))

print('\nFinished TRAINING.')

plt.plot(range(1, num_epochs + 1), loss_train_log, c='r', label='train')
plt.plot(epoch_val_log, loss_val_log, c='b', label='val')
plt.legend(loc='upper right')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

"""#### Loading and pre-processing of testing data

Now that we have trained a model, the next cells are about applying that model to the 500 subjects that are used for training the age regressor. Note, at a later stage you will also need to run the model on the 100 subjects from the hold-out set, once these have been made available. Before testing on the full set, you may want to initially just test on the 5 validation subjects to check everything is working fine.
"""

meta_data_reg_train = pd.read_csv(data_dir + 'meta/meta_data_reg_train.csv')
ids_seg_test = list(meta_data_reg_train['subject_id'])
files_seg_img_test = [data_dir + 'images/sub-' + f + '_T1w_unbiased.nii.gz' for f in ids_seg_test]
files_seg_seg_test = [data_dir + 'segs_refs/sub-' + f + '_T1w_seg.nii.gz' for f in ids_seg_test]
files_seg_msk_test = [data_dir + 'masks/sub-' + f + '_T1w_brain_mask.nii.gz' for f in ids_seg_test]

dataset_test = ImageSegmentationDataset(files_seg_img_test, files_seg_seg_test, files_seg_msk_test, img_spacing, img_size)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False)

"""#### Visualise testing example

Just to check how a testing image looks like after pre-processing.
"""

sample = dataset_test.get_sample(0)
img_name = dataset_test.get_img_name(0)
seg_name = dataset_test.get_seg_name(0)
print('Image: ' + img_name)
display_image(sample['img'], window=5, level=0)
print('Segmentation')
display_image(sitk.LabelToRGB(sample['seg']))
print('Mask')
display_image(sample['msk'])

"""#### TESTING

Below is an implementation of a full testing procedure that saves the segmentations in an output folder. Feel free to modify this procedure.

**TASK: You will need to add the calculations of Dice scores (and possibly others) to evaluate the segmentation performance.**
"""

pred_dir = os.path.join(out_dir, 'pred')
if not os.path.exists(pred_dir):
    os.makedirs(pred_dir)
model_dir = os.path.join(out_dir, 'model')

# model = UNet3D(1, num_classes)
model = SimpleNet3D(num_classes)
model.load_state_dict(torch.load(os.path.join(model_dir, 'model.pt')))
model.to(device)
model.eval()
    
print('START TESTING...')

loss_test = sum_pts = idx_test = 0
d_bgrnd, d_gm, d_wm, d_csf = [],[],[],[]
with torch.no_grad():
    for data_sample in dataloader_test:
        img, seg = data_sample['img'].to(device), data_sample['seg'].to(device)
        prd = model(img)
        prd_flat = prd.view(prd.size(0), prd.size(1), -1)
        seg_flat = seg.view(seg.size(0), seg.size(1), -1)
        loss_test += F.cross_entropy(prd_flat, seg_flat.squeeze(1), reduction='sum').item()
        sum_pts += seg_flat.size(2)        
        
        prd = torch.argmax(prd, dim=1)

        sample = dataset_test.get_sample(idx_test)
        name = dataset_test.get_seg_name(idx_test)
        prediction = sitk.GetImageFromArray(prd.cpu().squeeze().numpy().astype(np.uint8))
        prediction.CopyInformation(sample['seg'])
        sitk.WriteImage(prediction, os.path.join(pred_dir, name))

        # Compute and save Dice scores
        D = Dice_score(prd, seg)
        d_bgrnd.append(D['Background'])
        d_gm.append(D['GM'])
        d_wm.append(D['WM'])
        d_csf.append(D['CSF'])

        idx_test += 1
        print(idx_test)
        
loss_test /= sum_pts
bgrnd = sum(d_bgrnd) / len(d_bgrnd)
gm = sum(d_gm) / len(d_gm)
wm = sum(d_wm) / len(d_wm)
csf = sum(d_csf) / len(d_csf)

print(f'+ TESTING \tLoss: {loss_test:.6f} \tBground: {bgrnd:.4f} \tGM: {gm:.4f} \tWM: {wm:.4f} \tCSF: {csf:.4f}')

# Show last testing sample as an example
print('\n\nReference segmentation')
display_image(sitk.LabelToRGB(sample['seg']))
print('Predicted segmentation')
display_image(sitk.LabelToRGB(prediction))

print('\nFinished TESTING.')

import seaborn as sns
sns.set(style="darkgrid")
# Box and whiskers plot
data = pd.DataFrame(zip(d_bgrnd, d_gm, d_wm, d_csf), columns=('Background','GM','WM','CSF'))
fig, ax = plt.subplots(figsize=(12,12))
sns.boxplot(data=data, 
            orient='v',
            ax=ax
            )
plt.title('Dice scores by tissue class for the test set using the trained model')

"""### TASK A-2: Feature calculation

Start by calculating the three absolute tissue volumes for each subject. Plot the volumes against the subjects' ages. Taking the absolute volumes of tissues as features, however, might not be predictive. Instead, relative volumes need to be computed as the ratios between each tissue volume and overall brain volume. But you might also want to explore using different combinations or even polynomial features.

Implement a function that constructs a big matrix $X$ with a row for each subject and features across the columns. Start with just calculating three simple features of relative tissue volumes for GM, WM and CSF, and compare these to the absolute volumes plotted above.

*Note:* If you are struggling with the previous task on image segmentation, or if you prefer to work on this and the following tasks first, you can continue here using the provided reference segmentations which can be found in a subfolder `segs_refs`.
"""

## CALCULATE ABSOLUTE TISSUE VOLUMES
import pandas as pd
import numpy as np
import os

data_dir = 'data/brain_age/'

# USE THIS TO RUN THE CALCULATIONS ON YOUR SEGMENTATONS
seg_dir = './output/pred/'

# USE THIS TO RUN THE CALCULATIONS ON OUR REFERENCE SEGMENTATIONS
# seg_dir = data_dir + 'segs_refs/'

meta_data_reg_train = pd.read_csv(data_dir + 'meta/meta_data_reg_train.csv')
ids_reg_train = list(meta_data_reg_train['subject_id'])
files_reg_seg_train = [seg_dir + 'sub-' + f + '_T1w_seg.nii.gz' for f in ids_reg_train]

# THIS MATRIX WILL STORE THE VOLUMES PER TISSUE CLASS
vols = np.zeros((3,len(files_reg_seg_train)))

for idx, _ in enumerate(tqdm(range(len(files_reg_seg_train)), desc='Calculating Features')):
    
    seg_filename = files_reg_seg_train[idx]
    
    if os.path.exists(seg_filename):
        seg = sitk.ReadImage(seg_filename)
        
        ########################################
        # ADD YOUR CODE HERE
        ########################################
        seg = sitk.GetArrayFromImage(seg)
        
        for j in range(1,4):
            vols[j-1, idx] = len(np.where(seg == j)[0])

"""Plot features versus age."""

plt.figure(figsize=(12,8))
plt.scatter(vols[0,:],meta_data_reg_train['age'], marker='.')
plt.scatter(vols[1,:],meta_data_reg_train['age'], marker='.')
plt.scatter(vols[2,:],meta_data_reg_train['age'], marker='.')
plt.grid()
plt.title('Unnormalised')
plt.xlabel('Volume')
plt.ylabel('Age')
plt.legend(('CSF','GM','WM'))
plt.show()

## CALCULATE RELATIVE TISSUE VOLUMES

vols_normalised = np.zeros((3,len(files_reg_seg_train)))

########################################
# ADD YOUR CODE HERE
########################################

vols_normalised = vols / vols.sum(axis=0).reshape(1,-1)

assert np.absolute(vols_normalised.sum(axis=0) - 1).max() < 1e-6, "Something wrong with calculation"

"""Plot normalised features versus age."""

plt.figure(figsize=(12,8))
plt.scatter(vols_normalised[0,:],meta_data_reg_train['age'], marker='.')
plt.scatter(vols_normalised[1,:],meta_data_reg_train['age'], marker='.')
plt.scatter(vols_normalised[2,:],meta_data_reg_train['age'], marker='.')
plt.grid()
plt.title('Normalised')
plt.xlabel('Volume')
plt.ylabel('Age')
plt.legend(('CSF','GM','WM'))
plt.show()

"""Final data for age regression"""

X = vols_normalised.T
y = meta_data_reg_train['age'].values.reshape(-1,1)

print(X.shape)
print(y.shape)

"""### TASK A-3: Age regression and cross-validation

Experiment with different regression methods from the [scikit-learn toolkit](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Remember to construct the output vectur $y$ containing the age for each of the subjects.

Evaluate the methods using two-fold [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) where the dataset of 500 subjects is split into two equally sized sets $(X_1,y_1)$ and $(X_2,y_2)$ which are used for training and testing in an alternating way (so each set is used as $(X_{\text{train}},y_{\text{train}})$ and $(X_{\text{test}},y_{\text{test}})$ exactly once).

Try using at least three different regression methods, and generate a plot allows easy comparison of the performance of the three methods. Useful [error metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) to report include mean absolute error and r2 score. You might also want to plot the real vs predicted ages.

*Note:* These [scikit-learn examples](https://scikit-learn.org/stable/auto_examples/) might serve as an inspiration.

*Hint:* Be careful how you split the dataset into two folds. Take into account the data characteristics shown at the top of the notebook.
"""

cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda:" + cuda_dev if use_cuda else "cpu")

print('Device: ' + str(device))
if use_cuda:
    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))

########################################
# ADD YOUR CODE HERE
########################################
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn import linear_model
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

X = vols_normalised.T
y = meta_data_reg_train['age'].values.reshape(-1,1)

genders = meta_data_reg_train['gender_code'].values.reshape(-1,1) - 1
X = np.hstack((X, genders))

# Split data into two folds
X_1, X_2, y_1, y_2 = train_test_split(X, y, test_size=0.5, random_state=42)

#### METHOD 1: OLS REGRESSION ####

def model(X_a, X_b, y_a, y_b):

    def model_features(X, y):
        return X[:,(0,1,-1)], y

    X, y = model_features(X_a, y_a)

    # Fit model
    model = linear_model.LinearRegression()
    model.fit(X, y)
    w, b = model.coef_, model.intercept_ 

    # Test against val
    X_star, y = model_features(X_b, y_b)
    predicted = X_star @ w.T + b

    print('mean absolute error: {0}'.format(mean_absolute_error(y,predicted)))
    print('r2 score: {0}'.format(r2_score(y,predicted)))

    return predicted

print('\nModel preformance:')
pred = model(X_1, X_2, y_1, y_2)
pred = model(X_2, X_1, y_2, y_1)


#### METHOD 2: OLS WITH POLYNOMIAL FEATURES ####

def model_best(X_a, X_b, y_a, y_b, K=5):
    
    def create_design_matrix(X, K):
        '''Create design matrix for OLS with features
        K = num_features
        '''
        n, d = X.shape
        Phi = np.zeros((n, K*d))
        for i in range(1, K):
            Phi[:, i*d:(i+1)*d] = X ** i

        return Phi

    def model_features(X, y):
        return X[:,(0,1,-1)], y

    X, y = model_features(X_a, y_a)
    Phi = create_design_matrix(X, K)

    # Fit model
    # model = linear_model.Ridge(fit_intercept=False, alpha=0.1)
    model = linear_model.LinearRegression(fit_intercept=True)
    model.fit(Phi, y)
    w, b = model.coef_, model.intercept_ 

    # Test against val
    X_star, y = model_features(X_b, y_b)
    Phi_star = create_design_matrix(X_star, K)
    predicted = Phi_star @ w.T + b

    print('mean absolute error: {0}'.format(mean_absolute_error(y, predicted)))
    print('r2 score: {0}'.format(r2_score(y, predicted)))

    return predicted

print('\nModel preformance:')
pred_2 = model_best(X_1, X_2, y_1, y_2)
pred_1 = model_best(X_2, X_1, y_2, y_1)


#### METHOD 3: BAYESIAN RIDGE REGRESSION ####

def model(X_a, X_b, y_a, y_b):

    def model_features(X, y):
        return X[:,(0,1,-1)], y

    X, y = model_features(X_a, y_a)

    # Fit model
    model = linear_model.BayesianRidge()
    model.fit(X, y.squeeze())
    w, b = model.coef_, model.intercept_ 

    # Test against val
    X_star, y = model_features(X_b, y_b)
    predicted = X_star @ w.T + b

    print('mean absolute error: {0}'.format(mean_absolute_error(y, predicted)))
    print('r2 score: {0}'.format(r2_score(y, predicted)))

    return predicted

print('\nModel preformance:')
pred = model(X_1, X_2, y_1, y_2)
pred = model(X_2, X_1, y_2, y_1)


#### METHOD 4: MLP REGRESSION ####

class MLPRegressor(nn.Module):
    def __init__(self, in_features):
        super(MLPRegressor, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(in_features, 500),
            nn.ReLU(),
            nn.Linear(500, 200),
            nn.ReLU(),
            nn.Linear(200, 100),
            nn.ReLU(),
            nn.Linear(100, 1),
        )        

    def forward(self, x):
        return self.model(x.float())

    def loss(self, pred, y):
        rmse = ((pred - y)**2).sum()**0.5
        return rmse

def model(X_a, X_b, y_a, y_b, N_batches=10, epochs=100):

    batches_train = [(x, y) for x,y in zip(np.vsplit(X_a, N_batches), np.vsplit(y_a, N_batches))]
    batches_val = [(x, y) for x,y in zip(np.vsplit(X_b, N_batches), np.vsplit(y_b, N_batches))]
    
    mod = MLPRegressor(in_features=X_a.shape[1]).to(device)
    optimizer = torch.optim.Adam(mod.parameters(), lr=0.001)

    for epoch in range(epochs):

        mod.train()
        # Training loop
        train_loss = 0
        for idx, batch in enumerate(batches_train):
            X = torch.from_numpy(batch[0]).to(device)
            y = torch.from_numpy(batch[1]).to(device)

            optimizer.zero_grad()
            pred = mod(X)
            loss = mod.loss(pred, y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        train_loss /= len(batches_train)
        # print(f'TRAINING: Epoch {epoch} / {epochs} \t loss: {train_loss}')

        # Validation
        if epoch % 5 == 0:
            mod.eval()
            with torch.no_grad():
                val_loss = 0
                for idx, batch in enumerate(batches_val):
                    X = torch.from_numpy(batch[0]).to(device)
                    y = torch.from_numpy(batch[1]).to(device)

                    pred = mod(X)
                    loss = mod.loss(pred, y)
                    val_loss += loss.item()

                val_loss /= len(batches_val)
                # print(f'\nVALIDATION: \t loss: {val_loss}\n')

    # Generate predictions using trained model
    X = torch.from_numpy(X_b).to(device)
    predicted = mod(X).detach().cpu().numpy()
    y = y_b

    print('mean absolute error: {0}'.format(mean_absolute_error(y, predicted)))
    print('r2 score: {0}'.format(r2_score(y, predicted)))

    return predicted

print('\nModel preformance:')
pred = model(X_1, X_2, y_1, y_2)
pred = model(X_2, X_1, y_2, y_1)


#### CODE FOR PLOTS BELOW ####
predicted = np.vstack((pred_2.reshape(-1,1), pred_1.reshape(-1,1)))
y = np.vstack((y_2, y_1))
# print(y.shape, predicted.shape)

"""Error calculation and plotting"""

print('mean absolute error: {0}'.format(mean_absolute_error(y,predicted)))
print('r2 score: {0}'.format(r2_score(y,predicted)))

fig, ax = plt.subplots(figsize=(10,6))
ax.scatter(y, predicted, marker='.')
ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
ax.set_xlabel('Real Age')
ax.set_ylabel('Predicted Age')
plt.show()

meta_data_reg_test = pd.read_csv(data_dir + 'meta/meta_data_reg_test.csv')         # link: https://piazza.com/imperial.ac.uk/spring2020/co416/resources
ids_seg_test = list(meta_data_reg_test['subject_id'])
files_seg_img_test = [data_dir + 'images/sub-' + f + '_T1w_unbiased.nii.gz' for f in ids_seg_test]
files_seg_seg_test = [data_dir + 'segs_refs/sub-' + f + '_T1w_seg.nii.gz' for f in ids_seg_test]
files_seg_msk_test = [data_dir + 'masks/sub-' + f + '_T1w_brain_mask.nii.gz' for f in ids_seg_test]

dataset_test = ImageSegmentationDataset(files_seg_img_test, files_seg_seg_test, files_seg_msk_test, img_spacing, img_size)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False)

pred_dir = os.path.join(out_dir, 'pred')
if not os.path.exists(pred_dir):
    os.makedirs(pred_dir)
model_dir = os.path.join(out_dir, 'model')

# model = SimpleNet3D(1, num_classes)
model = SimpleNet3D(num_classes)
model.load_state_dict(torch.load(os.path.join(model_dir, 'model.pt')))
model.to(device)
model.eval()
    
print('START TESTING...')

loss_test = sum_pts = idx_test = 0
d_bgrnd, d_gm, d_wm, d_csf = [],[],[],[]
with torch.no_grad():
    for data_sample in dataloader_test:
        img, seg = data_sample['img'].to(device), data_sample['seg'].to(device)
        prd = model(img)
        prd_flat = prd.view(prd.size(0), prd.size(1), -1)
        seg_flat = seg.view(seg.size(0), seg.size(1), -1)
        loss_test += F.cross_entropy(prd_flat, seg_flat.squeeze(1), reduction='sum').item()
        sum_pts += seg_flat.size(2)        
        
        prd = torch.argmax(prd, dim=1)

        sample = dataset_test.get_sample(idx_test)
        name = dataset_test.get_seg_name(idx_test)
        prediction = sitk.GetImageFromArray(prd.cpu().squeeze().numpy().astype(np.uint8))
        prediction.CopyInformation(sample['seg'])
        sitk.WriteImage(prediction, os.path.join(pred_dir, name))

        # Compute and save Dice scores
        D = Dice_score(prd, seg)
        d_bgrnd.append(D['Background'])
        d_gm.append(D['GM'])
        d_wm.append(D['WM'])
        d_csf.append(D['CSF'])

        idx_test += 1
        print(idx_test)
        
loss_test /= sum_pts
bgrnd = sum(d_bgrnd) / len(d_bgrnd)
gm = sum(d_gm) / len(d_gm)
wm = sum(d_wm) / len(d_wm)
csf = sum(d_csf) / len(d_csf)

print(f'+ TESTING \tLoss: {loss_test:.6f} \tBground: {bgrnd:.4f} \tGM: {gm:.4f} \tWM: {wm:.4f} \tCSF: {csf:.4f}')

# Show last testing sample as an example
print('\n\nReference segmentation')
display_image(sitk.LabelToRGB(sample['seg']))
print('Predicted segmentation')
display_image(sitk.LabelToRGB(prediction))

print('\nFinished TESTING.')

"""### Evalutation on unseen 100 samples"""

## CALCULATE ABSOLUTE TISSUE VOLUMES

meta_data_reg_test = pd.read_csv(data_dir + 'meta/meta_data_reg_test.csv')
ids_reg_test = list(meta_data_reg_test['subject_id'])
files_reg_seg_test = [seg_dir + 'sub-' + f + '_T1w_seg.nii.gz' for f in ids_reg_test]

# THIS MATRIX WILL STORE THE VOLUMES PER TISSUE CLASS
vols_test = np.zeros((3,len(files_reg_seg_test)))

for idx, _ in enumerate(tqdm(range(len(files_reg_seg_test)), desc='Calculating Features')):
    
    seg_filename = files_reg_seg_test[idx]
    
    if os.path.exists(seg_filename):
        seg = sitk.ReadImage(seg_filename)
        
        ########################################
        # ADD YOUR CODE HERE
        ########################################
        seg = sitk.GetArrayFromImage(seg)
        
        for j in range(1,4):
            vols_test[j-1, idx] = len(np.where(seg == j)[0])

"""Plot features versus age."""

plt.figure(figsize=(12,8))
plt.scatter(vols_test[0,:],meta_data_reg_test['age'], marker='.')
plt.scatter(vols_test[1,:],meta_data_reg_test['age'], marker='.')
plt.scatter(vols_test[2,:],meta_data_reg_test['age'], marker='.')
plt.grid()
plt.title('Unnormalised')
plt.xlabel('Volume')
plt.ylabel('Age')
plt.legend(('CSF','GM','WM'))
plt.show()

## CALCULATE RELATIVE TISSUE VOLUMES

vols_normalised_test = np.zeros((3,len(files_reg_seg_test)))

########################################
# ADD YOUR CODE HERE
########################################

vols_normalised_test = vols_test / vols_test.sum(axis=0).reshape(1,-1)

assert np.absolute(vols_normalised_test.sum(axis=0) - 1).max() < 1e-6, "Something wrong with calculation"

"""Plot normalised features versus age."""

plt.figure(figsize=(12,8))
plt.scatter(vols_normalised_test[0,:],meta_data_reg_test['age'], marker='.')
plt.scatter(vols_normalised_test[1,:],meta_data_reg_test['age'], marker='.')
plt.scatter(vols_normalised_test[2,:],meta_data_reg_test['age'], marker='.')
plt.grid()
plt.title('Normalised')
plt.xlabel('Volume')
plt.ylabel('Age')
plt.legend(('CSF','GM','WM'))
plt.show()

"""Final data for age regression"""

X_test = vols_normalised_test.T
y_test = meta_data_reg_test['age'].values.reshape(-1,1)

print(X_test.shape)
print(y_test.shape)

cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda:" + cuda_dev if use_cuda else "cpu")

print('Device: ' + str(device))
if use_cuda:
    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))

########################################
# ADD YOUR CODE HERE
########################################

X_test = vols_normalised_test.T
y_test = meta_data_reg_test['age'].values.reshape(-1,1)

genders_test = meta_data_reg_test['gender_code'].values.reshape(-1,1) - 1
X_test = np.hstack((X_test, genders_test))

# Train model on full 500 samples and then evaluate on unseen test 100
X = vols_normalised.T
y = meta_data_reg_train['age'].values.reshape(-1,1)

genders = meta_data_reg_train['gender_code'].values.reshape(-1,1) - 1
print(genders.shape, X.shape)
X = np.hstack((X, genders))

assert len(X_test) == len(y_test), "Test data and labels are of different sizes"
assert len(X) == len(y), "Train data and labels are of different sizes"
print(X.shape, y.shape, X_test.shape, y_test.shape)

# Train using best model and pre
pred = model_best(X, X_test, y, y_test, K=5)

#### CODE FOR PLOTS BELOW ####
predicted = pred
y = y_test
print(y.shape, predicted.shape)

"""Error calculation and plotting"""

print('mean absolute error: {0:.4f}'.format(mean_absolute_error(y,predicted)))
print('r2 score: {0:.4f}'.format(r2_score(y,predicted)))

fig, ax = plt.subplots(figsize=(10,6))
ax.scatter(y, predicted, marker='.')
ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
ax.set_xlabel('Real Age')
ax.set_ylabel('Predicted Age')
plt.show()

"""## Part B: PCA-based regression using grey matter maps

The second approach will make use of grey matter maps that have been already extracted from the MRI scans and aligned to a common reference space to obtain spatially normalised maps. For this, we have used an advanced, state-of-the-art neuroimaging toolkit, called SPM12. The reference space corresponds to the commonly used MNI atlas as seen in the lecture on image segmentation.

Because these grey matter maps are spatially normalised (ie., registered), voxel locations across images from different subjects roughly correspond to the same anatomical locations. This means that each voxel location in the grey matter maps can be treated as an individual feature. Because those maps are quite large at their full resolution there would be a very large number of features to deal with (more than 850,000). A dimensionality reduction may need to be performed before training a suitable regressor on the low-dimensional feature representation. We will use Principal Component Analysis (PCA) to do the dimensionality reduction. It might also be beneficial to apply some pre-processing (downsampling, smoothing, etc.) before running PCA, which should be explored. The implemented pipeline should be evaluated using two-fold cross-validation using the same data splits as in part A for the 500 subjects, so the two different approaches can be directly compared in terms average age prediction accuracy.

*Note:* For part B, only the spatially normalised grey matter maps should be used.

### TASK B-1: Pre-processing

Before running PCA to reduce the dimensionality of the feature space for grey matter maps, it might be beneficial to run some pre-processing on the maps. In voxel-based analysis where each voxel location is a feature, it is common to apply some smoothing beforehand. This is to reduce noise and to compensate for errors of the spatial normalisation.

Because the maps are quite large, it might also be worthwile to explore whether downsampling could be performed even before PCA. This would further reduce the dimensionality, and might be even needed in the case where PCA on the orignial resolution runs into memory issues. You may want to consider other ways of pre-processing and you can find insipiration in the notebook on medical image computing `02-Intro-Medical-Image-Computing.ipynb`.

Implement a function that performs suitable pre-processing on each grey matter map.

*Hint:* You may want to save the pre-processed maps using `sitk.WriteImage` to avoid recomputation each time you run the notebook.
"""

########################################
# ADD YOUR CODE HERE
########################################

from sklearn.model_selection import train_test_split
from tqdm import tqdm_notebook as tqdm

meta_data_reg_train = pd.read_csv(data_dir + 'meta/meta_data_reg_train.csv')

# 1. Get train meta data
IDs = meta_data_reg_train['subject_id'].tolist()
ages = meta_data_reg_train['age'].tolist()

# 2. Grey matter map filenames
gm_filenames = [data_dir + 'greymatter/wc1sub-' + ID + '_T1w.nii.gz' for ID in IDs]

variances = [i for i in range(10)]
class PCADataset(Dataset):
    """Dataset for image segmentation."""

    def __init__(self, file_list_img, ages, img_spacing, img_size, smooth, edge=False, sharpen=False):
        self.samples = []
        self.img_names = []
        self.ages = ages

        for idx, _ in enumerate(tqdm(range(len(file_list_img)), desc='Loading Data')):
            
            # 1. Get image
            img_path = file_list_img[idx]
            img = sitk.Cast(sitk.ReadImage(img_path), sitk.sitkFloat32)

            # 2. Pre-process the image
            img = resample_image(img, img_spacing, img_size, is_label=False)
            
            if smooth in variances:
                img = sitk.DiscreteGaussian(img, gaussian_smooth)

            elif smooth == 'diffusion':
                img = sitk.GradientAnisotropicDiffusion(img)
                
            if edge:
                img = sitk.SobelEdgeDetection(img)

            if sharpen:
                img_sm = sitk.DiscreteGaussian(img, 1)
                a = img - img_sm
                img = img + a * 2               
                
            # 3. Append to the samples list
            self.samples.append(img)
            self.img_names.append(os.path.basename(img_path)) 

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, item):
        sample = self.samples[item]
        image = torch.from_numpy(sitk.GetArrayFromImage(sample)).unsqueeze(0)

        return image
    
    def get_sample(self, item):
        return self.samples[item]

    def get_img_name(self, item):
        return self.img_names[item]

    def get_seg_name(self, item):
        return self.seg_names[item]
    
    def split_data(self):
        
        numpy_samples = []
        
        for sample in self.samples:
            numpy_samples.append(sitk.GetArrayFromImage(sample).flatten())
        
        numpy_samples = np.array(numpy_samples)
        
        X_train, X_test, y_train, y_test = train_test_split(numpy_samples, self.ages, test_size=0.50, random_state=42)
        return X_train, X_test, y_train, y_test
    
    def get_data(self):
        numpy_samples = []
    
        for sample in self.samples:
            numpy_samples.append(sitk.GetArrayFromImage(sample).flatten())
        
        return np.array(numpy_samples), self.ages

"""## Pre-processing exploration

The following images indicate some of the filters we attempted to apply. In particular: Gaussian smoothening, anisotropic diffusion, edge detection and sharpening filters.

![alt text](https://drive.google.com/uc?id=18UmlYCX_RCuZHpYjATBIVodcyMY728DY)
![alt text](https://drive.google.com/uc?id=1pYS3yrKPglcB-Db_JKBnrIxDEqUJ5Fnh)
![alt text](https://drive.google.com/uc?id=1uDVKrjAcQ0gIR0wsiOD_HxmCyEWaOJeF)
![alt text](https://drive.google.com/uc?id=1d37tIWXaSdJJakbxBL-GwbaHQ0jSuAwJ)
![alt text](https://drive.google.com/uc?id=1vAHESlLPNHpLeZJdtjnBXlULS8oN7lST)
![alt text](https://drive.google.com/uc?id=1kRkc1ccwT_9P_YCBASZaDdbdBZ4SUhHA)

### TASK B-2: Dimensionality reduction

Implement dimensionality reduction for grey matter maps using [scitkit-learn's PCA](http://scikit-learn.org/stable/modules/decomposition.html#pca). PCA has an option to set the percentage of variance to be preserved (by setting the parameter `n_components` to a value between 0 and 1). The number of principal modes, that is the new dimensionality of the data, is then automatically determined. Try initially to preserve 95% of the variance (`n_components=0.95`).

*Note:* When dimensionality reduction is used as pre-processing step for supervised learning, as in this case, it is important that PCA is fitted to the training data only, but then applied to both the training and testing data. So make sure your implementation consists of two separate steps, 1) fitting the PCA model to $X_{\text{train}}$ (using the `fit` function), and 2) applying dimensionality reduction to $X_{\text{train}}$ and $X_{\text{test}}$ using the `transform` function.
"""

########################################
# ADD YOUR CODE HERE
########################################

from sklearn.decomposition import PCA

def PCA_process(X_train, X_test, y_train, y_test, n_components):
    pca1 = PCA(n_components=n_components)
    pca2 = PCA(n_components=n_components)
    pca1.fit(X_train)
    pca2.fit(X_test)

    # Fold 1 : fit onto X_train
    X_train1 = pca1.transform(X_train)
    X_test1 = pca1.transform(X_test)
    y_train1 = y_train
    y_test1 = y_test

    # Fold 2 : fit onto X_test
    X_test2 = pca2.transform(X_train)
    X_train2 = pca2.transform(X_test)
    y_train2 = y_test
    y_test2 = y_train
    
    return X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2



"""### TASK B-3: Age regression and cross-validation

Experiment with different regression methods from the [scikit-learn toolkit](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Evaluate the methods using two-fold [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) in the same way as for your approach in Part A so results can be directly compared. Generate the similar plots.

Try using at least three different regression methods.

*Hint:* Remember, when you use cross-validation where you swap training and testing sets in each fold, you need to fit PCA to the training set of each fold.
"""

# Prepare datasets with different processing for {Gaussian Variance, Number of PCA Components}:
datasets = []

for sharpen in [True, False]:
    for edge in [True, False]:
        for gaussian_smooth in [5, 6, 7, 8, 9, 10, 'diffusion']:
            for n_components in [0.8, 0.85, 0.9, 0.95]:
                dataset = PCADataset(gm_filenames, ages, img_spacing, img_size, gaussian_smooth, edge=edge, sharpen=sharpen)
                X_train, X_test, y_train, y_test = dataset.split_data()
                X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = PCA_process(X_train, X_test, y_train, y_test, n_components)

                datasets.append((X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2))

# Record datasets' characteristics
datasets_descriptions = {}
idx = 0
for sharpen in [True, False]:
    for edge in [True, False]:
        for gaussian_smooth in [3, 4, 5, 6, 7, 8, 'diffusion']:
            for n_components in [0.8, 0.85, 0.9, 0.95]:
                datasets_descriptions[idx] = (gaussian_smooth, n_components, edge, sharpen)
                idx+=1

"""# 1. SVR Regression: RBF"""

from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    
    av_per_dataset = []

    for C in [1e5, 5e5, 1e6, 5e6, 1e7, 5e7]:
        for gamma in [1e-4, 1e-5, 1e-6, 1e-7, 1e-8]:
            
            clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=.1)

            for cv in range(1, 3):
                if cv == 1:
                    clf.fit(X_train1, y_train1)
                    y_pred1 = clf.predict(X_test1)
                    mean1 = mean_absolute_error(y_test1, y_pred1)

                else:
                    clf.fit(X_train2, y_train2)
                    y_pred2 = clf.predict(X_test2)
                    mean2 = mean_absolute_error(y_test2, y_pred2)

            mean_error = (mean1 + mean2) / 2
            results[mean_error] = (idx, C, gamma)
            av_per_dataset.append(mean_error)
    
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.min(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# 2. SGD Regression"""

from sklearn.linear_model import SGDRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []
        
    for max_iter in [1e6, 1e7, 5e7]:
        for tol in [1e-1, 1e-2, 1e-4]:
            
            clf = SGDRegressor(max_iter=max_iter, tol=1e-3)

            for cv in range(1, 3):
                if cv == 1:
                    clf.fit(X_train1, y_train1)
                    y_pred1 = clf.predict(X_test1)
                    mean1 = mean_absolute_error(y_test1, y_pred1)

                else:
                    clf.fit(X_train2, y_train2)
                    y_pred2 = clf.predict(X_test2)
                    mean2 = mean_absolute_error(y_test2, y_pred2)

            mean_error = (mean1 + mean2) / 2
            results[mean_error] = (idx, max_iter, tol)
            av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.min(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# 3. Gaussian Process"""

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []
    
    for kernel in [DotProduct(), WhiteKernel(), RBF()]:
        

            clf = GaussianProcessRegressor(kernel=kernel, alpha=2.5, random_state=0)

            for cv in range(1, 3):
                if cv == 1:
                    clf.fit(X_train1, y_train1)
                    y_pred1 = clf.predict(X_test1)
                    mean1 = mean_absolute_error(y_test1, y_pred1)

                else:
                    clf.fit(X_train2, y_train2)
                    y_pred2 = clf.predict(X_test2)
                    mean2 = mean_absolute_error(y_test2, y_pred2)

            mean_error = (mean1 + mean2) / 2
            results[mean_error] = (idx, kernel)
            av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.min(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))



"""# 4. Adaboost"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []
    
    for n_estimators in [50, 100, 150, 200]:
        for max_depth in [1, 2, 10, 50]:
            for loss in ['ls', 'lad']:

                clf = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=0.1, max_depth=max_depth, random_state=0, loss=loss)

                for cv in range(1, 3):
                    if cv == 1:
                        clf.fit(X_train1, y_train1)
                        y_pred1 = clf.predict(X_test1)
                        mean1 = mean_absolute_error(y_test1, y_pred1)

                    else:
                        clf.fit(X_train2, y_train2)
                        y_pred2 = clf.predict(X_test2)
                        mean2 = mean_absolute_error(y_test2, y_pred2)

                mean_error = (mean1 + mean2) / 2
                results[mean_error] = (idx, n_estimators, max_depth, loss)
                av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.mean(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# 5. ElasticNet"""

from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []

    clf = ElasticNet(random_state=0)

    for cv in range(1, 3):
        if cv == 1:
            clf.fit(X_train1, y_train1)
            y_pred1 = clf.predict(X_test1)
            mean1 = mean_absolute_error(y_test1, y_pred1)

        else:
            clf.fit(X_train2, y_train2)
            y_pred2 = clf.predict(X_test2)
            mean2 = mean_absolute_error(y_test2, y_pred2)

    mean_error = (mean1 + mean2) / 2
    results[mean_error] = (idx)
    av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.mean(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# 6. Ridge Regression"""

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []
    
    for alpha in [0.01, 0.1, 1, 2, 10]:

                clf = Ridge(alpha=alpha)

                for cv in range(1, 3):
                    if cv == 1:
                        clf.fit(X_train1, y_train1)
                        y_pred1 = clf.predict(X_test1)
                        mean1 = mean_absolute_error(y_test1, y_pred1)

                    else:
                        clf.fit(X_train2, y_train2)
                        y_pred2 = clf.predict(X_test2)
                        mean2 = mean_absolute_error(y_test2, y_pred2)

                mean_error = (mean1 + mean2) / 2
                results[mean_error] = (idx)
                av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.mean(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# 7. Lasso Regression"""

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

results = {}

# Run extensive grid search
for idx, dataset in enumerate(datasets):
    
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = dataset
    av_per_dataset = []
    
    for alpha in [0.01, 0.1, 1, 2, 10]:

                clf = Lasso(alpha=alpha)

                for cv in range(1, 3):
                    if cv == 1:
                        clf.fit(X_train1, y_train1)
                        y_pred1 = clf.predict(X_test1)
                        mean1 = mean_absolute_error(y_test1, y_pred1)

                    else:
                        clf.fit(X_train2, y_train2)
                        y_pred2 = clf.predict(X_test2)
                        mean2 = mean_absolute_error(y_test2, y_pred2)

                mean_error = (mean1 + mean2) / 2
                results[mean_error] = (idx)
                av_per_dataset.append(mean_error)
            
    print('Dataset {} --> Minimum Error: {}'.format(idx, np.mean(av_per_dataset)))
    
best_error = np.min(list(results.keys()))
print('Best result: {}'.format(best_error))
print('Best dataset: {}'.format(results[best_error]))

"""# Best Model: SVM-RBF"""

from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score
import seaborn as sns

meta_data_reg_test = pd.read_csv(data_dir + 'meta/meta_data_reg_test.csv')

# 1. Get test meta data
IDs = meta_data_reg_test['subject_id'].tolist()
ages_test = meta_data_reg_test['age'].tolist()

# 2. Grey matter map filenames
gm_filenames_test = [data_dir + 'greymatter/wc1sub-' + ID + '_T1w.nii.gz' for ID in IDs]

img_sizes = [[60, 60, 60], [50, 50, 50], [40, 40, 40], [60, 60, 50], [60, 60, 40]]
img_spacing = [3, 3, 3]

# Cross validate for image size
for img_size in img_sizes:
    # RESULTS: Best data idx = 71-75. smoothening = 6, edge filter, 0.90 PCA
    gaussian_smooth = 6
    edge = True
    sharpen = False
    n_components = 0.9

    dataset = PCADataset(gm_filenames, ages, img_spacing, img_size, gaussian_smooth, edge=edge, sharpen=sharpen)
    X_train, X_test, y_train, y_test = dataset.split_data()
    X_train1, y_train1, X_test1, y_test1, X_train2, y_train2, X_test2, y_test2 = PCA_process(X_train, X_test, y_train, y_test, n_components)

    # 2. Initialise the BEST MODEL
    C = 50000000.0
    gamma = 1e-07
    clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=.1)

    for cv in range(1, 3):
        if cv == 1:
            clf.fit(X_train1, y_train1)
            y_pred1 = clf.predict(X_test1)
            mean1 = mean_absolute_error(y_test1, y_pred1)

        else:
            clf.fit(X_train2, y_train2)
            y_pred2 = clf.predict(X_test2)
            mean2 = mean_absolute_error(y_test2, y_pred2)

    mean_error = (mean1 + mean2) / 2
    
    print('{} ===> {}'.format(img_size, mean_error))

# RESULTS: Best data idx = 71-75. smoothening = 6, edge filter, 0.90 PCA
gaussian_smooth = 6
edge = True
sharpen = False
n_components = 0.9
img_size = [60, 60, 60]

dataset_train = PCADataset(gm_filenames, ages, img_spacing, img_size, gaussian_smooth, edge=edge, sharpen=sharpen)
dataset_test = PCADataset(gm_filenames_test, ages_test, img_spacing, img_size, gaussian_smooth, edge=edge, sharpen=sharpen)
X_train, y_train = dataset_train.get_data()
X_test, y_test = dataset_test.get_data()

pca = PCA(n_components=n_components)
pca.fit(X_train)
X_train = pca.transform(X_train)
X_test = pca.transform(X_test)


# 2. Initialise the BEST MODEL
C = 50000000.0
gamma = 1e-07

clf = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=.1)
clf.fit(X_train, y_train)


# 3. Record the results
predicted = clf.predict(X_test)
y_test = meta_data_reg_test['age'].values.reshape(-1,)

"""Error calculation and plotting"""

print('mean absolute error: {0:.4f}'.format(mean_absolute_error(y_test,predicted)))
print('r2 score: {0:.4f}'.format(r2_score(y_test,predicted)))

sns.set(style="darkgrid")
fig, ax = plt.subplots(figsize=(10,6))
ax.scatter(y_test, predicted, marker='.')
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
ax.set_xlabel('Real Age')
ax.set_ylabel('Predicted Age')
plt.show()

"""## Part C: CNN-based regression using grey matter maps

The third approach is similar in nature to the second approach in task B, but instead of using PCA for dimensionality reduction in order to use a more classical regression model, now we will use convolutional neural networks (CNNs) on the grey matter maps for predicting the subject's age directly.

You will need to implement a CNN model that takes a grey matter map as an input and maps it to a one-dimensional, real-valued output. A good starting point may be a LeNet-type architecture and adapt the last layers to convert the classification into a regression network. You should have all the necessary ingredients now from above tasks and the notebooks from the lab tutorials for how to set up a CNN model in PyTorch, how to implement a suitable training and testing routine, and how to run a two-fold cross-validation on the 500 subjects similar to tasks A and B.

*Note:* For part C, only the spatially normalised grey matter maps should be used. Similar to task A, you may want to set up a configuration for the CNN training that may also involve some resampling of the input data.
"""

! wget https://www.doc.ic.ac.uk/~bglocker/teaching/notebooks/brainage-data.zip
! unzip brainage-data.zip
! wget https://www.doc.ic.ac.uk/~bglocker/teaching/notebooks/meta_data_reg_test.csv
! pip install SimpleITK==1.2.2

########################################
# Imports for Model
########################################
from torch.nn import Module, Conv3d, ConvTranspose3d, Linear, ReLU, Sequential, Linear, Flatten, L1Loss, BatchNorm3d, Dropout, BatchNorm1d
from torch.optim import Adam, lr_scheduler
import numpy as np
from sklearn.model_selection import train_test_split
from torch import nn
import torch.nn.functional as F
import SimpleITK as sitk
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import os
import matplotlib.pyplot as plt
from tqdm import tqdm
import seaborn as sns
########################################
# End Imports
########################################

"""# Dataset & Preprocessing"""

########################################
# Create Dataset Class:
########################################

class ImageSegmentationDataset(Dataset):
    """Dataset for image segmentation."""

    def __init__(self, selected_ids, id_ages, smoothen=None, edgen=False):
        if smoothen is None:
            smoothen = 0
        print("Initialising Dataset")
        self.ids = selected_ids
        if edgen:  # resample_image(dts[0][0], [3, 3, 3], [60, 60, 50])
            self.samples = [torch.from_numpy(sitk.GetArrayFromImage(sitk.SobelEdgeDetection(sitk.DiscreteGaussian(resample_image(sitk.ReadImage(f"{data_dir}/greymatter/wc1sub-{ID}_T1w.nii.gz", sitk.sitkFloat32), [3, 3, 3], [60, 60, 50]), smoothen)))).unsqueeze(0) for ID in self.ids]
        else:
            self.samples = [torch.from_numpy(sitk.GetArrayFromImage(sitk.DiscreteGaussian(resample_image(sitk.ReadImage(f"{data_dir}/greymatter/wc1sub-{ID}_T1w.nii.gz", sitk.sitkFloat32), [3, 3, 3], [60, 60, 50]), smoothen))).unsqueeze(0) for ID in self.ids]

        # self.samples = [(sitk.DiscreteGaussian(sitk.ReadImage(f"{data_dir}/greymatter/wc1sub-{ID}_T1w.nii.gz", sitk.sitkFloat32), smoothen)) for ID in self.ids]
        self.targets = torch.tensor(id_ages, dtype=torch.float).view((-1, 1))
        print("Initialisation complete")

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, item):
        return self.samples[item], self.targets[item]

def resample_image(image, out_spacing=(1.0, 1.0, 1.0), out_size=None, is_label=False, pad_value=0):
    """Resamples an image to given element spacing and output size."""

    original_spacing = np.array(image.GetSpacing())
    original_size = np.array(image.GetSize())

    if out_size is None:
        out_size = np.round(np.array(original_size * original_spacing / np.array(out_spacing))).astype(int)
    else:
        out_size = np.array(out_size)

    original_direction = np.array(image.GetDirection()).reshape(len(original_spacing),-1)
    original_center = (np.array(original_size, dtype=float) - 1.0) / 2.0 * original_spacing
    out_center = (np.array(out_size, dtype=float) - 1.0) / 2.0 * np.array(out_spacing)

    original_center = np.matmul(original_direction, original_center)
    out_center = np.matmul(original_direction, out_center)
    out_origin = np.array(image.GetOrigin()) + (original_center - out_center)

    resample = sitk.ResampleImageFilter()
    resample.SetOutputSpacing(out_spacing)
    resample.SetSize(out_size.tolist())
    resample.SetOutputDirection(image.GetDirection())
    resample.SetOutputOrigin(out_origin.tolist())
    resample.SetTransform(sitk.Transform())
    resample.SetDefaultPixelValue(pad_value)

    if is_label:
        resample.SetInterpolator(sitk.sitkNearestNeighbor)
    else:
        resample.SetInterpolator(sitk.sitkBSpline)

    return resample.Execute(image)

"""# Model Architecture"""

DO_PRINT = True

class PrintTensor(nn.Module):
    # Custom helper layer to display shape of batch input/output
    def __init__(self, name="", do_print=DO_PRINT):
        super(PrintTensor, self).__init__()
        self.name=name
        self.do_print = do_print

    def forward(self, x):
        if self.do_print:
            print(f"{self.name}: {x.size()}")
        return x

class Part3(Module):
    """
    Neural Network for part 3.
    """

    def __init__(self, feats, dropout_p):
        super(Part3, self).__init__()
        self.model = Sequential(
            # 50, 60, 60
            Conv3d(1, feats, padding=0, kernel_size=3, stride=1, bias=True), 
            BatchNorm3d(feats),
            ReLU(),
            Conv3d(feats, feats, padding=0, kernel_size=3, stride=1, bias=True),
            BatchNorm3d(feats),
            ReLU(),
            Conv3d(feats, 2*feats, padding=0, kernel_size=2, stride=2, bias=True),
            Dropout(p=dropout_p),

            # 23, 28, 28
            Conv3d(2*feats, 2*feats, padding=0, kernel_size=3, stride=1, bias=True), 
            BatchNorm3d(2*feats),
            ReLU(),
            Conv3d(2*feats, 2*feats, padding=0, kernel_size=3, stride=1, bias=True),
            BatchNorm3d(2*feats),
            ReLU(),
            Conv3d(2*feats, 2*2*feats, padding=0, kernel_size=2, stride=2, bias=True),

            # 9, 12, 12
            Conv3d(2*2*feats, 2*2*feats, padding=0, kernel_size=3, stride=1, bias=True), 
            BatchNorm3d(2*2*feats),
            ReLU(),
            Conv3d(2*2*feats, 2*2*feats, padding=0, kernel_size=3, stride=1, bias=True), 
            BatchNorm3d(2*2*feats),
            ReLU(),
            Conv3d(2*2*feats, 2*2*2*feats, padding=0, kernel_size=1, stride=1, bias=True),
            Dropout(p=dropout_p),

            # 5, 8, 8
            Conv3d(2*2*2*feats, 2*2*2*feats, padding=0, kernel_size=3, stride=1, bias=True),
            # 3, 6, 6
            BatchNorm3d(2*2*2*feats),
            ReLU(),
            Conv3d(2*2*2*feats, 2*2*2*feats, padding=0, kernel_size=3, stride=1, bias=True), 
            # 1, 4, 4
            BatchNorm3d(2*2*2*feats),
            ReLU(),
            Conv3d(2*2*2*feats, 2*2*2*2*feats, padding=0, kernel_size=(1, 2, 2), stride=1, bias=True),
            Dropout(p=dropout_p),
            #  1, 3, 3
            Flatten(start_dim=1), # Output: 1
            Linear(2*2*2*2*feats*(1*3*3), 1),
            )

    def forward(self, x):
        return self.model(x)

"""# Dataset initialisation"""

data_dir = 'data/brain_age/'
training_size = 0.50
smoothen = 8
edgen = False
meta_data_reg_train = pd.read_csv(data_dir + 'meta/meta_data_reg_train.csv')
ids = meta_data_reg_train['subject_id'].tolist()
ages = meta_data_reg_train['age'].tolist()
X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(ids, ages, train_size=0.5, random_state=42)
# ImageSegmentationDataset
dataset1 = ImageSegmentationDataset(X_fold1, y_fold1, smoothen, edgen)
dataset2 = ImageSegmentationDataset(X_fold2, y_fold2, smoothen, edgen)

########################################
# User Parameters:
########################################
# Percentage Training Size (%)
USE_GPU = True
dtype = torch.float32
feats = 5
num_epochs = 200
lr = 0.006882801723742766
gamma = 0.97958263796472
batch_size = 32
dropout_p = 0.5
sns.set(style='darkgrid')
########################################
# End User Parameters
########################################

# Display GPU Settings:
cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)
use_cuda = torch.cuda.is_available()
device = torch.device("cuda:" + cuda_dev if use_cuda else "cpu")
print('Device: ' + str(device))
if use_cuda:
    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))

print("Creating Subject Folder")
number_here = 0
while True:
    fn = f'Subject_{number_here}'
    if not os.path.exists(fn):
        print(f"Making {number_here}")
        os.makedirs(fn)
        with open(f'{fn}/log.txt', 'w+') as log:
            log.write('\n')
        break
    else:
        print(f"Subject_{number_here} exists")
        number_here += 1
print("Created Subject Folder")

loss_function = L1Loss()

print(f"Learning Rate: {lr} and Feature Amplifier: {feats}, Num_epochs: {num_epochs}, Gamma: {gamma}")
folds_val_scores = []
for i in [0, 1]:
    training_loss = []
    val_loss_epoch5 = []
    i_fold_val_scores = []
    if i == 0:
        train_loader = DataLoader(dataset1, batch_size=batch_size)
        val_loader = DataLoader(dataset2, batch_size=batch_size)
    else:
        train_loader = DataLoader(dataset2, batch_size=batch_size)
        val_loader = DataLoader(dataset1, batch_size=batch_size)

    model = Part3(feats, dropout_p).to(device=device)

    params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total Params: {params}")
    
    optimizer = Adam(model.parameters(), lr, weight_decay=0.005)
    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma, last_epoch=-1)

    for epoch in range(num_epochs):
        model.train()
        epoch_loss = []
        for batch_data, batch_labels in train_loader:

            batch_labels = batch_labels.to(device=device)
            batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
            batch_preds = model(batch_data)
            loss = loss_function(batch_preds, batch_labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            epoch_loss.append(loss.item())

        training_MAE = np.mean(epoch_loss)
        training_loss.append(training_MAE)

        scheduler.step()

        if (epoch%5==0):
            val_loss = []
            model.eval()
            with torch.no_grad():
                for batch_data, batch_labels in val_loader:
                    batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
                    batch_labels = batch_labels.to(device=device)
                    batch_preds = model(batch_data)
                    loss = loss_function(batch_preds, batch_labels)
                    val_loss.append(loss.item())
                mean_val_error5 = np.mean(val_loss)
                val_loss_epoch5.append(mean_val_error5)
            print(f"Epoch: {epoch}:: Learning Rate: {scheduler.get_lr()[0]}")
            print(f"{number_here}::{i} Maxiumum Age Error: {np.round(np.max(epoch_loss))} Average Age Error: {training_MAE}, MAE Validation: {mean_val_error5}")
                
    model.eval()
    with torch.no_grad():
        for batch_data, batch_labels in val_loader:
            batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
            batch_labels = batch_labels.to(device=device)
            batch_preds = model(batch_data)
            loss = loss_function(batch_preds, batch_labels)
            i_fold_val_scores.append(loss.item())

    mean_fold_score = np.mean(i_fold_val_scores)
    val_loss_epoch5.append(mean_fold_score)
    print(f"Mean Age Error: {mean_fold_score}")

    folds_val_scores.append(mean_fold_score)

    plt.plot([epoch for epoch in range(num_epochs)], training_loss, color='b', label='Train')
    plt.plot([5*i for i in range(len(val_loss_epoch5))], val_loss_epoch5, color='r', label='Val')
    plt.title("Loss")
    plt.xlabel("Number of Epochs")
    plt.ylabel("Loss")
    plt.ylim(0, 30)
    plt.xlim(-5, num_epochs+5)
    plt.legend()
    plt.savefig(f'{fn}/graph_{i}.png')
    plt.close()

    if i == 0:
        train_0 = training_loss
        val_0 = val_loss_epoch5
    else:
        train_1 = training_loss
        val_1 = val_loss_epoch5

final_MAE = np.mean(folds_val_scores)
print(f"Average Loss on whole val set: {final_MAE}")

result = f"""
########################################################################
# Score = {final_MAE}

# Number of epochs:
num_epochs = {num_epochs}

# Batch size during training
batch_size = {batch_size}

# Learning rate for optimizers
lr = {lr}

# Size of feature amplifier
Feature Amplifier: {feats}


# Gamma (using sched)
Gamma: {gamma}

# Smooth:
smoothen = {smoothen}

# Edgen:
edgen = {edgen}

# Amount of dropout:
dropout_p = {dropout_p}

Total number of parameters is: {params}

# Model:
{model.__str__()}
########################################################################
"""

with open(f'{fn}/log.txt', 'a+') as log:
    log.write('\n')
    log.write(result)
    log.write('\n')
    torch.save(model, f'{fn}/model.pth')


plt.plot([epoch for epoch in range(num_epochs)], train_0, color='b', label='Train-0')
plt.plot([5*i for i in range(len(val_0))], val_0, color='r', label='Val-0')
plt.plot([epoch for epoch in range(num_epochs)], train_1, '--', color='b', label='Train-1')
plt.plot([5*i for i in range(len(val_1))], val_1, '-', color='r', label='Val-1')
plt.title("Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.ylim(0, 40)
plt.xlim(-5, num_epochs+5)
plt.legend()
plt.savefig(f'{fn}/cv_graph.png')
plt.close()

with open(f'{fn}/log.txt', 'a+') as log:
    log.write('\n')
    log.write(result)
    log.write('\n')
    torch.save(model, f'{fn}/model.pth')

"""# Full Train & Final Test"""

########################################
# User Parameters:
########################################
data_dir = 'data/brain_age/'
USE_GPU = True
dtype = torch.float32

smoothen = 8
edgen = False
feats = 5
num_epochs = 200
lr = 0.006882801723742766
gamma = 0.97958263796472
batch_size = 32
dropout_p = 0.5

########################################
# End User Parameters
########################################

meta_data_reg_train = pd.read_csv(data_dir + 'meta/meta_data_reg_train.csv')
train_ids = meta_data_reg_train['subject_id'].tolist()
train_ages = meta_data_reg_train['age'].tolist()

meta_data_reg_test = pd.read_csv('meta_data_reg_test.csv')
test_ids = meta_data_reg_test['subject_id'].tolist()
test_ages = meta_data_reg_test['age'].tolist()

# ImageSegmentationDataset
train_ds = ImageSegmentationDataset(train_ids, train_ages, smoothen, edgen)
test_ds = ImageSegmentationDataset(test_ids, test_ages, smoothen, edgen)

# Display GPU Settings:
cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)
use_cuda = torch.cuda.is_available()
device = torch.device("cuda:" + cuda_dev if use_cuda else "cpu")
print('Device: ' + str(device))
if use_cuda:
    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))

print("Creating Subject Folder")
number_here = 0
while True:
    fn = f'Test_{number_here}'
    if not os.path.exists(fn):
        print(f"Making {number_here}")
        os.makedirs(fn)
        with open(f'{fn}/log.txt', 'w+') as log:
            log.write('\n')
        break
    else:
        print(f"Test_{number_here} exists")
        number_here += 1
print("Created Subject Folder")

loss_function = L1Loss()
train_loader = DataLoader(train_ds, batch_size=batch_size)
test_loader = DataLoader(test_ds, batch_size=batch_size)
print(f"Learning Rate: {lr} and Feature Amplifier: {feats}, Num_epochs: {num_epochs}, Gamma: {gamma}")

training_loss = []
test_loss_epoch5 = []

model = Part3(feats, dropout_p).to(device=device)
params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total Params: {params}")
    
optimizer = Adam(model.parameters(), lr, weight_decay=0.005)
scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma, last_epoch=-1)

for epoch in range(num_epochs):
    model.train()
    epoch_loss = []
    for batch_data, batch_labels in train_loader:

        batch_labels = batch_labels.to(device=device)
        batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
        batch_preds = model(batch_data)
        loss = loss_function(batch_preds, batch_labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        epoch_loss.append(loss.item())

    training_MAE = np.mean(epoch_loss)
    training_loss.append(training_MAE)

    scheduler.step()

    if (epoch%5==0):
        test_loss = []
        model.eval()
        with torch.no_grad():
            for batch_data, batch_labels in test_loader:
                batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
                batch_labels = batch_labels.to(device=device)
                batch_preds = model(batch_data)
                loss = loss_function(batch_preds, batch_labels)
                test_loss.append(loss.item())
            mean_test_error5 = np.mean(test_loss)
            test_loss_epoch5.append(mean_test_error5)
        print(f"Epoch: {epoch}:: Learning Rate: {scheduler.get_lr()[0]}")
        print(f"{number_here}:: Maxiumum Age Error: {np.round(np.max(epoch_loss))} Average Age Error: {training_MAE}, MAE Test: {mean_test_error5}")
            
model.eval()
test_scores = []
with torch.no_grad():
    for batch_data, batch_labels in test_loader:
        batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
        batch_labels = batch_labels.to(device=device)
        batch_preds = model(batch_data)
        loss = loss_function(batch_preds, batch_labels)
        test_scores.append(loss.item())

score = np.mean(test_scores)
test_loss_epoch5.append(score)
print(f"Mean Age Error: {score}")

plt.plot([epoch for epoch in range(num_epochs)], training_loss, color='b', label='Train')
plt.plot([5*i for i in range(len(test_loss_epoch5))], test_loss_epoch5, color='r', label='Test')
plt.title("Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.ylim(0, 30)
plt.xlim(-5, num_epochs+5)
plt.legend()
plt.savefig(f'{fn}/test_loss_graph.png')
plt.close()

print(f"Average Loss on whole test set: {score}")

result = f"""
########################################################################
# Score = {score}

# Number of epochs:
num_epochs = {num_epochs}

# Batch size during training
batch_size = {batch_size}

# Learning rate for optimizers
lr = {lr}

# Size of feature amplifier
Feature Amplifier: {feats}

# Gamma (using sched)
Gamma: {gamma}

# Smooth:
smoothen = {smoothen}

# Edgen:
edgen = {edgen}

# Amount of dropout:
dropout_p = {dropout_p}

Total number of parameters is: {params}

# Model:
{model.__str__()}
########################################################################
"""

with open(f'{fn}/test_log.txt', 'a+') as log:
    log.write('\n')
    log.write(result)
    log.write('\n')
    torch.save(model, f'{fn}/test_model.pth')

model.eval()
pred_ages = []
actual_ages = []
with torch.no_grad():
    # for batch_data, batch_labels in train_loader:
    #     batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
    #     batch_labels = batch_labels.to(device=device)
    #     batch_preds = model(batch_data)
    #     pred_ages.append([batch_preds[i].item() for i in range(len(batch_preds))])
    #     actual_ages.append([batch_labels[i].item() for i in range(len(batch_labels))])

    for batch_data, batch_labels in test_loader:
        batch_data = batch_data.to(device=device)  # move to device, e.g. GPU
        batch_labels = batch_labels.to(device=device)
        batch_preds = model(batch_data)
        pred_ages.append([batch_preds[i].item() for i in range(len(batch_preds))])
        actual_ages.append([batch_labels[i].item() for i in range(len(batch_labels))])

pred_ages = np.array(pred_ages).flatten()
actual_ages = np.array(actual_ages).flatten()

pred_array = []
age_array = []
for i in range(len(pred_ages)):
    for j in range(len(pred_ages[i])):
        pred_array.append(pred_ages[i][j])
        age_array.append(actual_ages[i][j])

y = age_array
predicted = pred_array

fig, ax = plt.subplots()
ax.scatter(y, predicted, marker='.')
ax.plot([min(y), max(y)], [min(y), max(y)], 'k--', lw=2)
ax.set_xlabel('Real Age')
ax.set_ylabel('Predicted Age')
plt.savefig(f'{fn}/scatter_part_c.png')
plt.close()

"""![image.png](data:image/png;base64,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)"""